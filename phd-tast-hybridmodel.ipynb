{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6224754,"sourceType":"datasetVersion","datasetId":3575242},{"sourceId":8955407,"sourceType":"datasetVersion","datasetId":5389546}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.decomposition import PCA\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.ensemble import VotingClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Function to parse each line of the data\ndef parse_line(line):\n    parts = line.strip().split()\n    label, concentration = map(float, parts[0].split(';'))\n    features = [float(part.split(':')[1]) for part in parts[1:]]\n    return [label, concentration] + features\n\n# Data loading and preprocessing\ndata_directory = '/kaggle/input/gas-sensor-array-drift-dataset'\ndata_files = [f for f in os.listdir(data_directory) if f.endswith('.dat')]\ndata = []\n\nfor file_name in data_files:\n    file_path = os.path.join(data_directory, file_name)\n    with open(file_path, 'r') as file:\n        for line in file:\n            data.append(parse_line(line))\n\n# Convert data to DataFrame\ncolumn_names = ['label', 'concentration'] + [f'feature_{i}' for i in range(1, 129)]\ndata_frame = pd.DataFrame(data, columns=column_names)\n\n# Splitting the dataset into training and testing sets\nX = data_frame.iloc[:, 2:]  # Features\ny = data_frame.iloc[:, 0]   # Labels\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)\n\n# Feature scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Convert labels to one-hot encoding for the neural network\nnum_classes = y.nunique()\ny_train_encoded = to_categorical(y_train.astype(int) - 1)\ny_test_encoded = to_categorical(y_test.astype(int) - 1)\n\n# Define the neural network model\nnn_model = Sequential([\n    Input(shape=(X_train.shape[1],)),\n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(32, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(num_classes, activation='softmax')\n])\n\n# Compile the neural network model\nnn_model.compile(optimizer=Adam(learning_rate=0.001),\n                 loss='categorical_crossentropy',\n                 metrics=['accuracy'])\n\n# Train the neural network model\nnn_model.fit(X_train_scaled, y_train_encoded, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n\n# Define the Gradient Boosting model\ngb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\ngb_model.fit(X_train_scaled, y_train)\n\n# Combine both models into a voting classifier\nclass HybridModel:\n    def __init__(self, nn_model, gb_model):\n        self.nn_model = nn_model\n        self.gb_model = gb_model\n\n    def predict(self, X):\n        nn_pred = np.argmax(self.nn_model.predict(X), axis=1) + 1  # Neural network predictions\n        gb_pred = self.gb_model.predict(X)  # Gradient boosting predictions\n        # Combine predictions using majority vote\n        final_pred = np.array([np.argmax(np.bincount([nn, gb])) for nn, gb in zip(nn_pred, gb_pred)])\n        return final_pred\n\nhybrid_model = HybridModel(nn_model, gb_model)\n\n# Make predictions on the test set using the hybrid model\ny_pred = hybrid_model.predict(X_test_scaled)\n\n# Print classification report\nprint(classification_report(y_test, y_pred))\n\n# Perform PCA\npca = PCA(n_components=2)\nX_test_pca = pca.fit_transform(X_test_scaled)\n\n# Create a function to plot and save PCA results\ndef plot_pca(X_pca, y, y_pred, title, filename):\n    plt.figure(figsize=(12, 10))\n    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', alpha=0.7)\n    plt.colorbar(scatter, label='Batch')\n    plt.title(title)\n    plt.xlabel('PCA1')\n    plt.ylabel('PCA2')\n    plt.tight_layout()\n    plt.savefig(filename)\n    plt.close()\n\n# Plot and save original data\nplot_pca(X_test_pca, y_test, None, 'PCA of Original Test Data (All Batches)', 'pca_original_all_batches.png')\n\n# Plot and save predicted data\nplot_pca(X_test_pca, y_pred, None, 'PCA of Predicted Test Data (All Batches)', 'pca_predicted_all_batches.png')\n\n# Create a confusion matrix\nconf_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\nplt.figure(figsize=(12, 10))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.savefig('confusion_matrix.png')\nplt.close()\n\nprint(\"Figures have been saved: pca_original_all_batches.png, pca_predicted_all_batches.png, and confusion_matrix.png\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-15T07:19:44.546958Z","iopub.execute_input":"2024-07-15T07:19:44.547314Z","iopub.status.idle":"2024-07-15T07:26:08.592343Z","shell.execute_reply.started":"2024-07-15T07:19:44.547286Z","shell.execute_reply":"2024-07-15T07:26:08.591309Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-07-15 07:19:46.302366: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-15 07:19:46.302491: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-15 07:19:46.448697: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n\u001b[1m 83/331\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2577 - loss: 2.2518","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1721028006.357181     100 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.4220 - loss: 1.6749 - val_accuracy: 0.8543 - val_loss: 0.5188\nEpoch 2/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7369 - loss: 0.7324 - val_accuracy: 0.9047 - val_loss: 0.3206\nEpoch 3/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8151 - loss: 0.5438 - val_accuracy: 0.9618 - val_loss: 0.2124\nEpoch 4/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8568 - loss: 0.4398 - val_accuracy: 0.9610 - val_loss: 0.1729\nEpoch 5/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.3640 - val_accuracy: 0.9735 - val_loss: 0.1352\nEpoch 6/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.3192 - val_accuracy: 0.9686 - val_loss: 0.1401\nEpoch 7/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.3120 - val_accuracy: 0.9637 - val_loss: 0.1343\nEpoch 8/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9035 - loss: 0.3121 - val_accuracy: 0.9724 - val_loss: 0.1166\nEpoch 9/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2668 - val_accuracy: 0.9595 - val_loss: 0.1225\nEpoch 10/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2594 - val_accuracy: 0.9690 - val_loss: 0.1265\nEpoch 11/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.2655 - val_accuracy: 0.9516 - val_loss: 0.1383\nEpoch 12/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.2574 - val_accuracy: 0.9383 - val_loss: 0.1720\nEpoch 13/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2494 - val_accuracy: 0.9614 - val_loss: 0.1297\nEpoch 14/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9227 - loss: 0.2571 - val_accuracy: 0.9784 - val_loss: 0.0944\nEpoch 15/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.2130 - val_accuracy: 0.9860 - val_loss: 0.0940\nEpoch 16/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.2314 - val_accuracy: 0.9546 - val_loss: 0.1296\nEpoch 17/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.2006 - val_accuracy: 0.9860 - val_loss: 0.0779\nEpoch 18/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9403 - loss: 0.2073 - val_accuracy: 0.9834 - val_loss: 0.0785\nEpoch 19/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.2061 - val_accuracy: 0.9879 - val_loss: 0.0798\nEpoch 20/20\n\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.1851 - val_accuracy: 0.9792 - val_loss: 0.0892\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n              precision    recall  f1-score   support\n\n         1.0       0.99      1.00      1.00       102\n         2.0       0.96      1.00      0.98       127\n         3.0       1.00      0.96      0.98        90\n         4.0       1.00      0.99      1.00       116\n         5.0       1.00      0.99      1.00       172\n         6.0       1.00      1.00      1.00        89\n\n    accuracy                           0.99       696\n   macro avg       0.99      0.99      0.99       696\nweighted avg       0.99      0.99      0.99       696\n\nFigures have been saved: pca_original_all_batches.png, pca_predicted_all_batches.png, and confusion_matrix.png\n","output_type":"stream"}]}]}